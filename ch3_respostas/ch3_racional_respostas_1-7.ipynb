{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Describe the null hypotheses to which the p-values given in Table 3.4  correspond. Explain what conclusions you can draw based on these\n",
    "p-values. Your explanation should be phrased in terms of sales, TV, radio, and newspaper, rather than in terms of the coefficients of the\n",
    "linear model.\n",
    "\n",
    "A hipótese nula para cada variável dependente descreve acerca do seu impacto nas vendas enquanto veículo de propaganda, pragmaticamente a hipótese nula diz que os veículos de propganda não possuem impacto nas vendas. O t-statistic para TV e Radio são bastante positivos associados a valores P negativos, indicando que o coeficiente de calculado tem provavel real impacto no aumento de vendas, o que favorece a hipótese alternativa: estes veículos específicos impactam na venda.\n",
    "\n",
    "Já para Jornais a situação é oposta, o t-statistic é negativo e o valor P é positivo, indicando que o coeficiente calculado não tem impacto nas vendas, o que favorece a hipótese nula: este veículo específico não impacta na venda.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Carefully explain the differences between the KNN classifier and KNN regression methods.\n",
    "\n",
    "Ambos os métodos tem em comum apenas uma característica: recorrem aos dados existentes dentro de um raio especificado pelo usuário para inferir um resultado. Porém servem a propósitos distintos.\n",
    "KNN classifier busca encaixar pontos existentes dentro de categorias definidas enquanto o KNN regression tenta prever o próximo ponto de uma curva dentro de uma distribuição.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.897\n",
      "Model:                            OLS   Adj. R-squared:                  0.896\n",
      "Method:                 Least Squares   F-statistic:                     570.3\n",
      "Date:                Mon, 13 Nov 2023   Prob (F-statistic):           1.58e-96\n",
      "Time:                        10:09:36   Log-Likelihood:                -386.18\n",
      "No. Observations:                 200   AIC:                             780.4\n",
      "Df Residuals:                     196   BIC:                             793.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.9389      0.312      9.422      0.000       2.324       3.554\n",
      "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
      "Radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
      "Newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
      "==============================================================================\n",
      "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
      "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
      "Kurtosis:                       6.332   Cond. No.                         454.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('../datasets/Advertising.csv')\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols(\"Sales ~ TV + Radio + Newspaper\", df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Suppose we have a data set with five predictors, X1 = GPA, X2 = IQ, X3 = Level (1 for College and 0 for High School), X4 = Interaction between GPA and IQ, and X5 = Interaction between GPA and Level. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get ˆ #0 = 50, ˆ #1 = 20, ˆ #2 = 0.07, ˆ #3 = 35, ˆ #4 = 0.01, ˆ #5 = −10.\n",
    "\n",
    "(a) Which answer is correct, and why?\n",
    "i. For a fixed value of IQ and GPA, high school graduates earn more, on average, than college graduates.\n",
    "\n",
    "ii. For a fixed value of IQ and GPA, college graduates earn more, on average, than high school graduates.\n",
    "\n",
    "iii. For a fixed value of IQ and GPA, high school graduates earn more, on average, than college graduates provided that the GPA is high enough.\n",
    "\n",
    "iv. For a fixed value of IQ and GPA, college graduates earn more, on average, than high school graduates provided that the GPA is high enough.\n",
    "\n",
    "RESPOSTAS:\n",
    "\n",
    "i. Errada, há um acréscimo de 35 mil dólares no salário inicial ara quem possui graduação\n",
    "ii. Correta. (Correção: errada. depende do valor de GPA)\n",
    "iii. Talvez possa estar certa em pontos específicos após um dado valor de GPA, dado que o efeito do GPA sobre alunos do ensino médio é maior do que sobre graduados da faculdade. Seria necessário achar o ponto da curva onde se cruzam e ver se é um valor factível para a realidade.\n",
    "iv. Considerando o ponto iii, antes de um certo valor de GPA provavelmente está correto.\n",
    "\n",
    "\n",
    "(b) Predict the salary of a college graduate with IQ of 110 and a GPA of 4.0.\n",
    "\n",
    "salario =  50 + 20 * GPA+ 0.07 * IQ + 35 * (Level) + 0.01 * (GPA * IQ) - 10(GPA * Level)\n",
    "\n",
    "GPA =4, IQ = 110, LEVEL = 1 \n",
    "\n",
    "salario = 137,1\n",
    "\n",
    "\n",
    "(c) True or false: Since the coefficient for the GPA/IQ interaction  term is very small, there is very little evidence of an interaction effect. Justify your answer.\n",
    "\n",
    "O valor do coeficiente nada tem a ver com sua validade em termos de evidência. Para fazer essa afirmação é necessário checar a t-statistic, F-statstic, associtadas com  p-value para tomar uma decisão nesse sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. Y =#0 + #1X + #2X2 + #3X3 + \".\n",
    "\n",
    "\n",
    "(a) Suppose that the true relationship between X and Y is linear, i.e. Y = #0 + #1X + \". Consider the training residual sum of squares (RSS) for the linear regression, and also the training\n",
    "RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "\n",
    "Resposta: Não há informações suficientes para fazer essa comparação.\n",
    "\n",
    "Gabarito não oficial: Cubic regression will have lower Residual Sum of Squares (RSS). The cubic regression model is more flexible than the linear regression model. Accordingly, the cubic regression model can fit the data better and achieve a lower training RSS than the linear regression model.\n",
    "\n",
    "(b) Answer (a) using test rather than training RSS.\n",
    "\n",
    "Gabarito não oficial: Linear regression will have lower RSS. In general, more flexible models have less bias and higher variance. By contrast, more rigid models have high bias and lower variance. Since it is said that true relationship between the predictor and the response is linear, we know that, in this case, the linear regression model will have low bias. Consequently, this model will perform better than the cubic regression model, which is expected to have higher variance.\n",
    "\n",
    "\n",
    "(c) Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "\n",
    "Gabarito não oficial: Cubic regression will have lower RSS. Same reason as in (a). Since the model is more flexible, it is able to fit the data better.\n",
    "\n",
    "(d) Answer (c) using test rather than training RSS\n",
    "\n",
    "Gabarito não oficial:Not enough information to tell. Due to its flexibility, it is generally expected that the cubic regression model has lower bias and higher variance than the linear regression model. In this exercise, we know that the true relationship is non-linear, but we don't know how far it is from linear. This means that we don't have any idea about how high the bias of the linear regression model can be. If the model is just slightly non-linear, the linear regression will be able to model the data and achieve low bias. Thus, we would expect the linear model to have low bias and low variance. This could be enough (or not) to beat the cubic regression model, which is expected to have low bias and high variance. However, if the true relationship is substantially non-linear, the linear model will not be able to model the data and its bias will be high. With high bias and low variance, the linear regression model is beaten by a cubic model without overfitting problems. It will always depend on the bias-variance trade-off and, in general, on the size of the training set and the magnitude of the noise. We would need more information to know which model would have lower RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Descrição da Imagem](../arquivos_auxiliares/ch3_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Using (3.4), argue that in the case of simple linear regression, the least squares line always passes through the point (¯x, ¯y).\n",
    "![Descrição da Imagem](../arquivos_auxiliares/ch3_6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is claimed in the text that in the case of simple linear regression of Y onto X, the R2 statistic (3.17) is equal to the square of the correlation between X and Y (3.18). Prove that this is the case. For simplicity, you may assume that ¯x = ¯y = 0.\n",
    "\n",
    "\n",
    "![Descrição da Imagem](../arquivos_auxiliares/ch3_7.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
